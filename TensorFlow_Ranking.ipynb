{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow-Ranking.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lc0/deeplearning-playground/blob/master/TensorFlow_Ranking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Gna4eybzplge",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Install Bazel"
      ]
    },
    {
      "metadata": {
        "id": "vDXp-0XmqYkc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BAZEL_VERSION = '0.20.0'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n1vQOSE-prlH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "e6f4f552-8205-4788-ade7-1f865162d936"
      },
      "cell_type": "code",
      "source": [
        "!wget https://github.com/bazelbuild/bazel/releases/download/{BAZEL_VERSION}/bazel-{BAZEL_VERSION}-installer-linux-x86_64.sh"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-10 15:29:16--  https://github.com/bazelbuild/bazel/releases/download/0.20.0/bazel-0.20.0-installer-linux-x86_64.sh\n",
            "Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/20773773/16e3fc80-f4b8-11e8-9fbb-d3e0922a0573?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20181210%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20181210T152916Z&X-Amz-Expires=300&X-Amz-Signature=f98ba187e351896e863f79a884f95b47e8afcc62b55d53083885ff6c12adea96&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dbazel-0.20.0-installer-linux-x86_64.sh&response-content-type=application%2Foctet-stream [following]\n",
            "--2018-12-10 15:29:16--  https://github-production-release-asset-2e65be.s3.amazonaws.com/20773773/16e3fc80-f4b8-11e8-9fbb-d3e0922a0573?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20181210%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20181210T152916Z&X-Amz-Expires=300&X-Amz-Signature=f98ba187e351896e863f79a884f95b47e8afcc62b55d53083885ff6c12adea96&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dbazel-0.20.0-installer-linux-x86_64.sh&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.133.147\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.133.147|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170853024 (163M) [application/octet-stream]\n",
            "Saving to: ‘bazel-0.20.0-installer-linux-x86_64.sh.1’\n",
            "\n",
            "bazel-0.20.0-instal 100%[===================>] 162.94M  85.8MB/s    in 1.9s    \n",
            "\n",
            "2018-12-10 15:29:18 (85.8 MB/s) - ‘bazel-0.20.0-installer-linux-x86_64.sh.1’ saved [170853024/170853024]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KRV52PsIqB-c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!chmod +x bazel-{BAZEL_VERSION}-installer-linux-x86_64.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OMzQo6_9lzit",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3046
        },
        "outputId": "5b9bb0af-759b-4919-b308-84d8ba29e246"
      },
      "cell_type": "code",
      "source": [
        "!./bazel-{BAZEL_VERSION}-installer-linux-x86_64.sh"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bazel installer\n",
            "---------------\n",
            "\n",
            "Bazel is bundled with software licensed under the GPLv2 with Classpath exception.\n",
            "You can find the sources next to the installer on our release page:\n",
            "   https://github.com/bazelbuild/bazel/releases\n",
            "\n",
            "# Release 0.20.0 (2018-11-30)\n",
            "\n",
            "Baseline: 7bf7f031c332dc483257248d1c1f98ad75bbc83b\n",
            "\n",
            "Cherry picks:\n",
            "\n",
            "   + fd52341505e725487c6bc6dfbe6b5e081aa037da:\n",
            "     update bazel-toolchains pin to latest release Part of changes to\n",
            "     allow bazelci to use 0.19.0 configs. RBE toolchain configs at or\n",
            "     before 0.17.0 are not compatible with bazel 0.19.0 or above.\n",
            "   + 241f28d05424db2d11ee245dc856b992258505e3:\n",
            "     Revert \"Toggle --incompatible_disable_late_bound_option_defaults\n",
            "     flag.\"\n",
            "   + f7e5aef145c33968f658eb2260e25630dc41cc67:\n",
            "     Add cc_toolchain targets for the new entries in the default\n",
            "     cc_toolchain_suite.\n",
            "   + d2920e32ec7f3f8551a693d33c17b19f1b802145:\n",
            "     Revert \"WindowsFileSystem: open files with delete-sharing\"\n",
            "\n",
            "[Breaking changes in 0.20](https://github.com/bazelbuild/bazel/issues?q=is%3Aissue+label%3Abreaking-change-0.20)\n",
            "\n",
            "  - [--incompatible_remove_native_http_archive](https://github.com/bazelbuild/bazel/issues/6570).\n",
            "  - [--incompatible_remove_native_git_repository](https://github.com/bazelbuild/bazel/issues/6569).\n",
            "  - [--incompatible_disable_cc_toolchain_label_from_crosstool_proto](https://github.com/bazelbuild/bazel/issues/6434).\n",
            "  - [--incompatible_disable_depset_in_cc_user_flags](https://github.com/bazelbuild/bazel/issues/6384).\n",
            "  - [--incompatible_disable_cc_configuration_make_variables](https://github.com/bazelbuild/bazel/issues/6381).\n",
            "  - [--incompatible_disallow_conflicting_providers](https://github.com/bazelbuild/bazel/issues/5902).\n",
            "  - [--incompatible_range_type](https://github.com/bazelbuild/bazel/issues/5264).\n",
            "\n",
            "[0.20 is a migration window for the following changes](https://github.com/bazelbuild/bazel/issues?q=is%3Aissue+label%3Amigration-0.20)\n",
            "\n",
            "  - [--incompatible_use_jdk10_as_host_javabase](https://github.com/bazelbuild/bazel/issues/6661)\n",
            "  - [--incompatible_use_remotejdk_as_host_javabase](https://github.com/bazelbuild/bazel/issues/6656)\n",
            "  - [--incompatible_disable_sysroot_from_configuration](https://github.com/bazelbuild/bazel/issues/6565)\n",
            "  - [--incompatible_provide_cc_toolchain_info_from_cc_toolchain_suite](https://github.com/bazelbuild/bazel/issues/6537)\n",
            "  - [--incompatible_disable_depset_in_cc_user_flags](https://github.com/bazelbuild/bazel/issues/6383)\n",
            "  - [--incompatible_package_name_is_a_function](https://github.com/bazelbuild/bazel/issues/5827)\n",
            "\n",
            "[Breaking changes in the next release (0.21)](https://github.com/bazelbuild/bazel/issues?q=is%3Aissue+label%3Abreaking-change-0.21)\n",
            "\n",
            "  - [--incompatible_use_jdk10_as_host_javabase](https://github.com/bazelbuild/bazel/issues/6661)\n",
            "  - [--incompatible_use_remotejdk_as_host_javabase](https://github.com/bazelbuild/bazel/issues/6656)\n",
            "  - [--incompatible_disable_sysroot_from_configuration](https://github.com/bazelbuild/bazel/issues/6565)\n",
            "  - [--incompatible_provide_cc_toolchain_info_from_cc_toolchain_suite](https://github.com/bazelbuild/bazel/issues/6537)\n",
            "  - [--incompatible_disable_depset_in_cc_user_flags](https://github.com/bazelbuild/bazel/issues/6383)\n",
            "  - [--incompatible_disallow_data_transition](https://github.com/bazelbuild/bazel/issues/6153)\n",
            "  - [--incompatible_package_name_is_a_function](https://github.com/bazelbuild/bazel/issues/5827)\n",
            "  - [--incompatible_disallow_slash_operator](https://github.com/bazelbuild/bazel/issues/5823)\n",
            "  - [--incompatible_static_name_resolution](https://github.com/bazelbuild/bazel/issues/5637)\n",
            "\n",
            "Incompatible changes:\n",
            "\n",
            "  - the --experimental_no_dotd_scanning_with_modules command line\n",
            "    argument is not supported anymore.\n",
            "  - The --prune_cpp_modules command line option is not supported\n",
            "    anymore.\n",
            "  - the --experimental_prune_cpp_input_discovery command line option\n",
            "    is not supported anymore.\n",
            "\n",
            "New features:\n",
            "\n",
            "  - Added support for Android NDK r18.\n",
            "\n",
            "Important changes:\n",
            "\n",
            "  - The 'default' parameter of attr.output and attr.output_list is\n",
            "    removed. This is controlled by\n",
            "    --incompatible_no_output_attr_default\n",
            "  - A number of platform-related Starlark APIs which were previously\n",
            "    marked \"experimental\" are now disabled by default, and may be\n",
            "    enabled via --experimental_platforms_api\n",
            "  - Make legacy-test-support (\"legacy_test-<api-level>\") from\n",
            "    android_sdk_repository neverlink. The legacy test support\n",
            "    libraries shouldn't be built into test binaries. To make them\n",
            "    available at runtime, developers should declare them via\n",
            "    uses-library:\n",
            "    https://developer.android.com/training/testing/set-up-project#andr\n",
            "    oid-test-base\n",
            "  - query remote server Capabilities (per REAPI v2)\n",
            "  - CppRules: All cc_toolchains depended on from\n",
            "    cc_toolchain_suite.toolchains are now analyzed when not using\n",
            "    platforms in order to select the right cc_toolchain.\n",
            "  - removed obsolete --explicit_jre_deps flag.\n",
            "  - Incompatible flag\n",
            "    --incompatible_disable_legacy_cpp_toolchain_skylark_api was\n",
            "    flipped.\n",
            "  - Improve error messaging when unsupport proguard options are\n",
            "    specified at the library level.\n",
            "  - Incompatible flag\n",
            "    --incompatible_disable_legacy_cpp_toolchain_skylark_api was\n",
            "    flipped.\n",
            "  - Incompatible flag\n",
            "    --incompatible_disable_legacy_cpp_toolchain_skylark_api was\n",
            "    flipped.\n",
            "  - The --incompatible_disable_late_bound_option_defaults flag has\n",
            "    been flipped (#6384)\n",
            "  - Incompatible flag\n",
            "    --incompatible_disable_legacy_flags_cc_toolchain_api was flipped\n",
            "    (#6434)\n",
            "  - Fixed issue where ctx.resolve_command created conflicting\n",
            "    intermediate files when resolve_command was called multiple times\n",
            "    within the same rule invocation with a long command attribute.\n",
            "  - Incompatible flag\n",
            "    --incompatible_disable_cc_configuration_make_variables was\n",
            "    flipped (#6381)\n",
            "  - If the --javabase flag is unset, it Bazel locates a JDK using\n",
            "    the JAVA_HOME environment variable and searching the PATH. If no\n",
            "    JDK is found --javabase will be empty, and builds targeting Java\n",
            "    will not\n",
            "    be supported. Previously Bazel would fall back to using the\n",
            "    embedded\n",
            "    JDK as a --javabase, but this is no longer default behaviour. A\n",
            "    JDK should\n",
            "    be explicitly installed instead to enable Java development\n",
            "  - Bazel will now shut down when idle for 5 minutes and the system\n",
            "    is low on RAM (linux only).\n",
            "  - CROSSTOOL file is now read from the package of cc_toolchain, not\n",
            "    from\n",
            "    the package of cc_toolchain_suite. This is not expected to break\n",
            "    anybody since\n",
            "    cc_toolchain_suite and cc_toolchain are commonly in the same\n",
            "    package.\n",
            "  - All overrides of Starlark's ctx.new_file function are now\n",
            "    deprecated.\n",
            "      Try the `--incompatible_new_actions_api` flag to ensure your\n",
            "    code is forward-compatible.\n",
            "  - --incompatible_disable_cc_toolchain_label_from_crosstool_proto\n",
            "    was flipped.\n",
            "  - Introduce --(no)shutdown_on_low_sys_mem startup flag to toggle\n",
            "    idle low-memory shutdown, disabled by default.\n",
            "  - --incompatible_disable_cc_toolchain_label_from_crosstool_proto\n",
            "    was flipped.\n",
            "  - --incompatible_disable_cc_toolchain_label_from_crosstool_proto\n",
            "    was flipped.\n",
            "  - CppRules: All cc_toolchains depended on from\n",
            "    cc_toolchain_suite.toolchains are now analyzed when not using\n",
            "    platforms in order to select the right cc_toolchain.\n",
            "  - The function `attr.license` is deprecated and will be removed.\n",
            "      It can be disabled now with `--incompatible_no_attr_license`.\n",
            "  - `range()` function now returns a lazy value\n",
            "    (`--incompatible_range_type` is now set by default).\n",
            "  - The code coverage report now includes the actual paths to header\n",
            "    files instead of the ugly,\n",
            "    Bazel generated, virtual includes path.\n",
            "  - `--incompatible_disallow_conflicting_providers` has been switched\n",
            "    to true\n",
            "  - Add new flag `--incompatible_disable_systool_from_configration` to\n",
            "    disable loading the systool from CppConfiguration.\n",
            "  - Add new flag `--incompatible_disable_sysroot_from_configuration`\n",
            "    to\n",
            "    disable loading the systool from CppConfiguration.\n",
            "  - Sorting remote Platform properties for remote execution. May\n",
            "    affect cache keys!\n",
            "  - Use different server log files per Bazel server process; java.log\n",
            "    is\n",
            "    now a symlink to the latest log.\n",
            "\n",
            "This release contains contributions from many people at Google, as well as a7g4 <a7g4@a7g4.net>, Alan <alan.agius@betssongroup.com>, Asaf Flescher <asafflesch@gmail.com>, Benjamin Peterson <bp@benjamin.pe>, Ed Schouten <ed.schouten@prodrive-technologies.com>, George Gensure <ggensure@uber.com>, George Kalpakas <kalpakas.g@gmail.com>, Greg <gregestren@users.noreply.github.com>, Irina Iancu <iirina@users.noreply.github.com>, Keith Smiley <keithbsmiley@gmail.com>, Loo Rong Jie <loorongjie@gmail.com>, Mark Zeren <mzeren@vmware.com>, Petros Eskinder <petroseskinder@users.noreply.github.com>, rachcatch <rachelcatchpoole@hotmail.com>, Robert Brown <robert.brown@gmail.com>, Robert Gay <robert.gay@redfin.com>, Salty Egg <2281521+zhouhao@users.noreply.github.com>.\n",
            "\n",
            "## Build informations\n",
            "   - [Commit](https://github.com/bazelbuild/bazel/commit/2987897)\n",
            "Uncompressing.......\n",
            "\n",
            "Bazel is now installed!\n",
            "\n",
            "Make sure you have \"/usr/local/bin\" in your path. You can also activate bash\n",
            "completion by adding the following line to your ~/.bashrc:\n",
            "  source /usr/local/lib/bazel/bin/bazel-complete.bash\n",
            "\n",
            "See http://bazel.build/docs/getting-started.html to start a new project!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vykCPwS4mCdY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !export PATH=\"$PATH:$HOME/bin:/root/bin\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zswxtT0qp51z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "5b3b6b4f-df0f-4ccd-e1b8-e650c9e5d34c"
      },
      "cell_type": "code",
      "source": [
        "!bazel"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO: Invocation ID: 245f34d4-e6f7-4167-a261-07bb066b6de1\n",
            "                                                          [bazel release 0.20.0]\n",
            "Usage: bazel <command> <options> ...\n",
            "\n",
            "Available commands:\n",
            "  analyze-profile     Analyzes build profile data.\n",
            "  aquery              Analyzes the given targets and queries the action graph.\n",
            "  build               Builds the specified targets.\n",
            "  canonicalize-flags  Canonicalizes a list of bazel options.\n",
            "  clean               Removes output files and optionally stops the server.\n",
            "  coverage            Generates code coverage report for specified test targets.\n",
            "  cquery              Loads, analyzes, and queries the specified targets w/ configurations.\n",
            "  dump                Dumps the internal state of the bazel server process.\n",
            "  fetch               Fetches external repositories that are prerequisites to the targets.\n",
            "  help                Prints help for commands, or the index.\n",
            "  info                Displays runtime info about the bazel server.\n",
            "  license             Prints the license of this software.\n",
            "  mobile-install      Installs targets to mobile devices.\n",
            "  print_action        Prints the command line args for compiling a file.\n",
            "  query               Executes a dependency graph query.\n",
            "  run                 Runs the specified target.\n",
            "  shutdown            Stops the bazel server.\n",
            "  sync                Syncs all repositories specifed in the workspace file\n",
            "  test                Builds and runs the specified test targets.\n",
            "  version             Prints version information for bazel.\n",
            "\n",
            "Getting more help:\n",
            "  bazel help <command>\n",
            "                   Prints help and options for <command>.\n",
            "  bazel help startup_options\n",
            "                   Options for the JVM hosting bazel.\n",
            "  bazel help target-syntax\n",
            "                   Explains the syntax for specifying targets.\n",
            "  bazel help info-keys\n",
            "                   Displays a list of keys used by the info command.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UrYxxRYur3Sp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Qpm0f55sWZC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tensorflow Ranking"
      ]
    },
    {
      "metadata": {
        "id": "1QDXLQ1esZRl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd89856c-b772-45fe-ee0a-ac78ac873bce"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tensorflow/ranking.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ranking' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KKILdJuzscDq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ad93ade-c012-4c5b-c802-7ba41cc7fa8b"
      },
      "cell_type": "code",
      "source": [
        "%cd ranking/"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ranking\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XeFThbZBvQWy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "ac59f033-8a5a-482a-b90c-8abdb1cc734a"
      },
      "cell_type": "code",
      "source": [
        "!ls -laF"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 44\n",
            "drwxr-xr-x 4 root root  4096 Dec 10 15:17 ./\n",
            "drwxr-xr-x 1 root root  4096 Dec 10 15:29 ../\n",
            "-rw-r--r-- 1 root root  1101 Dec 10 15:17 CONTRIBUTING.md\n",
            "drwxr-xr-x 8 root root  4096 Dec 10 15:17 .git/\n",
            "-rw-r--r-- 1 root root 11362 Dec 10 15:17 LICENSE\n",
            "-rw-r--r-- 1 root root  6644 Dec 10 15:17 README.md\n",
            "drwxr-xr-x 5 root root  4096 Dec 10 15:17 tensorflow_ranking/\n",
            "-rw-r--r-- 1 root root    43 Dec 10 15:17 WORKSPACE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aJtKmyGKsgZO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "2b4b92a4-9350-4b73-cfb6-a80423b761f8"
      },
      "cell_type": "code",
      "source": [
        "!bazel build //tensorflow_ranking/tools/pip_package:build_pip_package"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: ignoring LD_PRELOAD in environment.\n",
            "Starting local Bazel server and connecting to it...\n",
            "\u001b[32mINFO: \u001b[0mInvocation ID: a8d4ed4d-e489-4e3c-9523-96395e8f541c\n",
            "\u001b[32mLoading:\u001b[0m 0 packages loaded\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow_ranking/tools/pip_package:build_pip_package (2 \\\n",
            "packages loaded)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow_ranking/tools/pip_package:build_pip_package (2 \\\n",
            "packages loaded)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow_ranking/tools/pip_package:build_pip_package (2 \\\n",
            "packages loaded)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow_ranking/tools/pip_package:build_pip_package (2 \\\n",
            "packages loaded)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow_ranking/tools/pip_package:build_pip_package (3 \\\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow_ranking/tools/pip_package:build_pip_package (3 \\\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow_ranking/tools/pip_package:build_pip_package (4 \\\n",
            "packages loaded, 17 targets configured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow_ranking/tools/pip_package:build_pip_package (10\\\n",
            " packages loaded, 47 targets configured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow_ranking/tools/pip_package:build_pip_package (14\\\n",
            "\u001b[32mINFO: \u001b[0mAnalysed target //tensorflow_ranking/tools/pip_package:build_pip_package (14 packages loaded, 111 targets configured).\n",
            "\u001b[32mINFO: \u001b[0mFound 1 target...\n",
            "Target //tensorflow_ranking/tools/pip_package:build_pip_package up-to-date:\n",
            "  bazel-bin/tensorflow_ranking/tools/pip_package/build_pip_package\n",
            "\u001b[32mINFO: \u001b[0mElapsed time: 6.130s, Critical Path: 0.04s\n",
            "\u001b[32mINFO: \u001b[0m0 processes.\n",
            "\u001b[32mINFO:\u001b[0m Build completed successfully, 4 total actions\n",
            "\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HkOMwBRR5Utj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1139
        },
        "outputId": "96435e15-5d3a-4575-8cde-814d68416d85"
      },
      "cell_type": "code",
      "source": [
        "!bazel-bin/tensorflow_ranking/tools/pip_package/build_pip_package /tmp/ranking_pip"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Dec 10 16:14:12 UTC 2018 : === Preparing sources in dir: /tmp/tmp.gSGyLkJMlf\n",
            "Mon Dec 10 16:14:12 UTC 2018 : === Building wheel\n",
            "running bdist_wheel\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/tensorflow_ranking\n",
            "copying tensorflow_ranking/__init__.py -> build/lib/tensorflow_ranking\n",
            "creating build/lib/tensorflow_ranking/python\n",
            "copying tensorflow_ranking/python/losses.py -> build/lib/tensorflow_ranking/python\n",
            "copying tensorflow_ranking/python/__init__.py -> build/lib/tensorflow_ranking/python\n",
            "copying tensorflow_ranking/python/utils.py -> build/lib/tensorflow_ranking/python\n",
            "copying tensorflow_ranking/python/model.py -> build/lib/tensorflow_ranking/python\n",
            "copying tensorflow_ranking/python/data.py -> build/lib/tensorflow_ranking/python\n",
            "copying tensorflow_ranking/python/feature.py -> build/lib/tensorflow_ranking/python\n",
            "copying tensorflow_ranking/python/version.py -> build/lib/tensorflow_ranking/python\n",
            "copying tensorflow_ranking/python/metrics.py -> build/lib/tensorflow_ranking/python\n",
            "copying tensorflow_ranking/python/head.py -> build/lib/tensorflow_ranking/python\n",
            "installing to build/bdist.linux-x86_64/wheel\n",
            "running install\n",
            "running install_lib\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/wheel\n",
            "creating build/bdist.linux-x86_64/wheel/tensorflow_ranking\n",
            "copying build/lib/tensorflow_ranking/__init__.py -> build/bdist.linux-x86_64/wheel/tensorflow_ranking\n",
            "creating build/bdist.linux-x86_64/wheel/tensorflow_ranking/python\n",
            "copying build/lib/tensorflow_ranking/python/losses.py -> build/bdist.linux-x86_64/wheel/tensorflow_ranking/python\n",
            "copying build/lib/tensorflow_ranking/python/__init__.py -> build/bdist.linux-x86_64/wheel/tensorflow_ranking/python\n",
            "copying build/lib/tensorflow_ranking/python/utils.py -> build/bdist.linux-x86_64/wheel/tensorflow_ranking/python\n",
            "copying build/lib/tensorflow_ranking/python/model.py -> build/bdist.linux-x86_64/wheel/tensorflow_ranking/python\n",
            "copying build/lib/tensorflow_ranking/python/data.py -> build/bdist.linux-x86_64/wheel/tensorflow_ranking/python\n",
            "copying build/lib/tensorflow_ranking/python/feature.py -> build/bdist.linux-x86_64/wheel/tensorflow_ranking/python\n",
            "copying build/lib/tensorflow_ranking/python/version.py -> build/bdist.linux-x86_64/wheel/tensorflow_ranking/python\n",
            "copying build/lib/tensorflow_ranking/python/metrics.py -> build/bdist.linux-x86_64/wheel/tensorflow_ranking/python\n",
            "copying build/lib/tensorflow_ranking/python/head.py -> build/bdist.linux-x86_64/wheel/tensorflow_ranking/python\n",
            "running install_egg_info\n",
            "running egg_info\n",
            "creating tensorflow_ranking.egg-info\n",
            "writing tensorflow_ranking.egg-info/PKG-INFO\n",
            "writing dependency_links to tensorflow_ranking.egg-info/dependency_links.txt\n",
            "writing requirements to tensorflow_ranking.egg-info/requires.txt\n",
            "writing top-level names to tensorflow_ranking.egg-info/top_level.txt\n",
            "writing manifest file 'tensorflow_ranking.egg-info/SOURCES.txt'\n",
            "reading manifest file 'tensorflow_ranking.egg-info/SOURCES.txt'\n",
            "writing manifest file 'tensorflow_ranking.egg-info/SOURCES.txt'\n",
            "Copying tensorflow_ranking.egg-info to build/bdist.linux-x86_64/wheel/tensorflow_ranking-0.1.0-py3.6.egg-info\n",
            "running install_scripts\n",
            "creating build/bdist.linux-x86_64/wheel/tensorflow_ranking-0.1.0.dist-info/WHEEL\n",
            "creating 'dist/tensorflow_ranking-0.1.0-py2.py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "adding 'tensorflow_ranking/__init__.py'\n",
            "adding 'tensorflow_ranking/python/__init__.py'\n",
            "adding 'tensorflow_ranking/python/data.py'\n",
            "adding 'tensorflow_ranking/python/feature.py'\n",
            "adding 'tensorflow_ranking/python/head.py'\n",
            "adding 'tensorflow_ranking/python/losses.py'\n",
            "adding 'tensorflow_ranking/python/metrics.py'\n",
            "adding 'tensorflow_ranking/python/model.py'\n",
            "adding 'tensorflow_ranking/python/utils.py'\n",
            "adding 'tensorflow_ranking/python/version.py'\n",
            "adding 'tensorflow_ranking-0.1.0.dist-info/METADATA'\n",
            "adding 'tensorflow_ranking-0.1.0.dist-info/WHEEL'\n",
            "adding 'tensorflow_ranking-0.1.0.dist-info/top_level.txt'\n",
            "adding 'tensorflow_ranking-0.1.0.dist-info/RECORD'\n",
            "removing build/bdist.linux-x86_64/wheel\n",
            "Mon Dec 10 16:14:12 UTC 2018 : === Output wheel file is in: /tmp/ranking_pip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-11nN0oA5RoU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "33e9d557-f71b-49ad-8f32-13a477726456"
      },
      "cell_type": "code",
      "source": [
        "!pip install /tmp/ranking_pip/tensorflow_ranking*.whl"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /tmp/ranking_pip/tensorflow_ranking-0.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-ranking==0.1.0) (1.12.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-ranking==0.1.0) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-ranking==0.1.0) (1.14.6)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-ranking==0.1.0) (0.6.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->tensorflow-ranking==0.1.0) (3.6.1)\n",
            "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->tensorflow-ranking==0.1.0) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->tensorflow-ranking==0.1.0) (1.0.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->tensorflow-ranking==0.1.0) (0.32.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->tensorflow-ranking==0.1.0) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->tensorflow-ranking==0.1.0) (1.0.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->tensorflow-ranking==0.1.0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->tensorflow-ranking==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.12.0->tensorflow-ranking==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow>=1.12.0->tensorflow-ranking==0.1.0) (40.6.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow>=1.12.0->tensorflow-ranking==0.1.0) (0.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow>=1.12.0->tensorflow-ranking==0.1.0) (3.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow>=1.12.0->tensorflow-ranking==0.1.0) (2.8.0)\n",
            "Installing collected packages: tensorflow-ranking\n",
            "Successfully installed tensorflow-ranking-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V5V8E64v5DDG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Python part"
      ]
    },
    {
      "metadata": {
        "id": "Epf88HAR6q-i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Dependencies and Global Variables**\n",
        "\n",
        "Let us start by importing libraries that will be used throughout this Notebook. We also enable the \"eager execution\" mode for convenience and demonstration purposes."
      ]
    },
    {
      "metadata": {
        "id": "0EcRGmWs5Bpc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7cceeaa-0df3-482e-93fe-145dc3a48512"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_ranking as tfr\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "tf.executing_eagerly()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "5MZ3-A4Q60x5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we will define some global parameters.\n"
      ]
    },
    {
      "metadata": {
        "id": "GL56ZMTlsqiY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Store the paths to files containing training and test instances.\n",
        "# As noted above, we will assume the data is in the LibSVM format\n",
        "# and that the content of each file is sorted by query ID.\n",
        "_TRAIN_DATA_PATH=\"tensorflow_ranking/examples/data/train.txt\"\n",
        "_TEST_DATA_PATH=\"tensorflow_ranking/examples/data/test.txt\"\n",
        "\n",
        "# Define a loss function. To find a complete list of available\n",
        "# loss functions or to learn how to add your own custom function\n",
        "# please refer to the tensorflow_ranking.losses module.\n",
        "_LOSS=\"pairwise_logistic_loss\"\n",
        "\n",
        "# In the TF-Ranking framework, a training instance is represented\n",
        "# by a Tensor that contains features from a list of documents\n",
        "# associated with a single query. For simplicity, we fix the shape\n",
        "# of these Tensors to a maximum list size and call it \"list_size,\"\n",
        "# the maximum number of documents per query in the dataset.\n",
        "# In this demo, we take the following approach:\n",
        "#   * If a query has fewer documents, its Tensor will be padded\n",
        "#     appropriately.\n",
        "#   * If a query has more documents, we shuffle its list of\n",
        "#     documents and trim the list down to the prescribed list_size.\n",
        "_LIST_SIZE=100\n",
        "\n",
        "# The total number of features per query-document pair.\n",
        "# We set this number to the number of features in the MSLR-Web30K\n",
        "# dataset.\n",
        "_NUM_FEATURES=136\n",
        "\n",
        "# Parameters to the scoring function.\n",
        "_BATCH_SIZE=32\n",
        "_HIDDEN_LAYER_DIMS=[\"20\", \"10\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c4m0gyaw65PM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Input Pipeline\n",
        "\n",
        "The first step to construct an input pipeline that reads your dataset and produces a `tensorflow.data.Dataset` object. In this example, we will invoke a LibSVM parser that is included in the `tensorflow_ranking.data` module to generate a `Dataset` from a given file.\n",
        "\n",
        "We parameterize this function by a `path` argument so that the function can be used to read both training and test data files."
      ]
    },
    {
      "metadata": {
        "id": "dIlPYSnxtRS4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def input_fn(path):\n",
        "  train_dataset = tf.data.Dataset.from_generator(\n",
        "      tfr.data.libsvm_generator(path, _NUM_FEATURES, _LIST_SIZE),\n",
        "      output_types=(\n",
        "          {str(k): tf.float32 for k in range(1,_NUM_FEATURES+1)},\n",
        "          tf.float32\n",
        "      ),\n",
        "      output_shapes=(\n",
        "          {str(k): tf.TensorShape([_LIST_SIZE, 1])\n",
        "            for k in range(1,_NUM_FEATURES+1)},\n",
        "          tf.TensorShape([_LIST_SIZE])\n",
        "      )\n",
        "  )\n",
        "\n",
        "  train_dataset = train_dataset.shuffle(1000).repeat().batch(_BATCH_SIZE)\n",
        "  return train_dataset.make_one_shot_iterator().get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bFbaod0V8Hic",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Scoring Function\n",
        "\n",
        "Next, we turn to the scoring function which is arguably at the heart of a TF Ranking model. The idea is to compute a relevance score for a (set of) query-document pair(s). The TF-Ranking model will use training data to learn this function.\n",
        "\n",
        "Here we formulate a scoring function using a feed forward network. The function takes the features of a single example (i.e., query-document pair) and produces a relevance score."
      ]
    },
    {
      "metadata": {
        "id": "akY3ZWR-tTVo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def example_feature_columns():\n",
        "  \"\"\"Returns the example feature columns.\"\"\"\n",
        "  feature_names = [\n",
        "      \"%d\" % (i + 1) for i in range(0, _NUM_FEATURES)\n",
        "  ]\n",
        "  return {\n",
        "      name: tf.feature_column.numeric_column(\n",
        "          name, shape=(1,), default_value=0.0) for name in feature_names\n",
        "  }\n",
        "\n",
        "def make_score_fn():\n",
        "  \"\"\"Returns a scoring function to build `EstimatorSpec`.\"\"\"\n",
        "\n",
        "  def _score_fn(context_features, group_features, mode, params, config):\n",
        "    \"\"\"Defines the network to score a documents.\"\"\"\n",
        "    del params\n",
        "    del config\n",
        "    # Define input layer.\n",
        "    example_input = [\n",
        "        tf.layers.flatten(group_features[name])\n",
        "        for name in sorted(example_feature_columns())\n",
        "    ]\n",
        "    input_layer = tf.concat(example_input, 1)\n",
        "\n",
        "    cur_layer = input_layer\n",
        "    for i, layer_width in enumerate(int(d) for d in _HIDDEN_LAYER_DIMS):\n",
        "      cur_layer = tf.layers.dense(\n",
        "          cur_layer,\n",
        "          units=layer_width,\n",
        "          activation=\"tanh\")\n",
        "\n",
        "    logits = tf.layers.dense(cur_layer, units=1)\n",
        "    return logits\n",
        "\n",
        "  return _score_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n-QS4TYa8LBK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluation Metrics\n",
        "\n",
        "We have provided an implementation of popular Information Retrieval evalution metrics in the TF Ranking library."
      ]
    },
    {
      "metadata": {
        "id": "UhS4WDoyunb7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def eval_metric_fns():\n",
        "  \"\"\"Returns a dict from name to metric functions.\n",
        "\n",
        "  This can be customized as follows. Care must be taken when handling padded\n",
        "  lists.\n",
        "\n",
        "  def _auc(labels, predictions, features):\n",
        "    is_label_valid = tf_reshape(tf.greater_equal(labels, 0.), [-1, 1])\n",
        "    clean_labels = tf.boolean_mask(tf.reshape(labels, [-1, 1], is_label_valid)\n",
        "    clean_pred = tf.boolean_maks(tf.reshape(predictions, [-1, 1], is_label_valid)\n",
        "    return tf.metrics.auc(clean_labels, tf.sigmoid(clean_pred), ...)\n",
        "  metric_fns[\"auc\"] = _auc\n",
        "\n",
        "  Returns:\n",
        "    A dict mapping from metric name to a metric function with above signature.\n",
        "  \"\"\"\n",
        "  metric_fns = {}\n",
        "  metric_fns.update({\n",
        "      \"metric/ndcg@%d\" % topn: tfr.metrics.make_ranking_metric_fn(\n",
        "          tfr.metrics.RankingMetricKey.NDCG, topn=topn)\n",
        "      for topn in [1, 3, 5, 10]\n",
        "  })\n",
        "\n",
        "  return metric_fns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1FB1ALEZ8QBy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Putting It All Together\n",
        "\n",
        "We are now ready to put all of the components above together and create an `Estimator` that can be used to train and evaluate a model."
      ]
    },
    {
      "metadata": {
        "id": "u5pDz4Ec5zE0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_estimator(hparams):\n",
        "  \"\"\"Create a ranking estimator.\n",
        "\n",
        "  Args:\n",
        "    hparams: (tf.contrib.training.HParams) a hyperparameters object.\n",
        "\n",
        "  Returns:\n",
        "    tf.learn `Estimator`.\n",
        "  \"\"\"\n",
        "  def _train_op_fn(loss):\n",
        "    \"\"\"Defines train op used in ranking head.\"\"\"\n",
        "    return tf.contrib.layers.optimize_loss(\n",
        "        loss=loss,\n",
        "        global_step=tf.train.get_global_step(),\n",
        "        learning_rate=hparams.learning_rate,\n",
        "        optimizer=\"Adagrad\")\n",
        "\n",
        "  ranking_head = tfr.head.create_ranking_head(\n",
        "      loss_fn=tfr.losses.make_loss_fn(_LOSS),\n",
        "      eval_metric_fns=eval_metric_fns(),\n",
        "      train_op_fn=_train_op_fn)\n",
        "\n",
        "  return tf.estimator.Estimator(\n",
        "      model_fn=tfr.model.make_groupwise_ranking_fn(\n",
        "          group_score_fn=make_score_fn(),\n",
        "          group_size=1,\n",
        "          transform_fn=None,\n",
        "          ranking_head=ranking_head),\n",
        "      params=hparams)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zv-2HCeV8WFN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let us instantiate and initialize the `Estimator` we defined above."
      ]
    },
    {
      "metadata": {
        "id": "BlQHT8S_52bG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "1744323b-f7fd-491a-c8c7-7be214ef895f"
      },
      "cell_type": "code",
      "source": [
        "hparams = tf.contrib.training.HParams(learning_rate=0.05)\n",
        "ranker = get_estimator(hparams)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpm3tx4sz3\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpm3tx4sz3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7faa5f6e77f0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cyTuWPpD8bed",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that we have a correctly initialized `Estimator`, we will train a model using the training data. We encourage you to experiment with different number of steps here and below."
      ]
    },
    {
      "metadata": {
        "id": "1bvdFw_555A3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "99ee5b92-3d8e-42e7-d5a2-d7a04b3f22bc"
      },
      "cell_type": "code",
      "source": [
        "ranker.train(input_fn=lambda: input_fn(_TRAIN_DATA_PATH), steps=100)\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Use groupwise dnn v2.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpm3tx4sz3/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.93946236, step = 0\n",
            "INFO:tensorflow:Saving checkpoints for 100 into /tmp/tmpm3tx4sz3/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.05830523.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.estimator.estimator.Estimator at 0x7faa5f6e7358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "8AtKl-qJ8ff9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, let us evaluate our model on the test set."
      ]
    },
    {
      "metadata": {
        "id": "nJ-7lzgg56-X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "a14fca9e-8654-4b43-ca6f-94c667b7c325"
      },
      "cell_type": "code",
      "source": [
        "ranker.evaluate(input_fn=lambda: input_fn(_TEST_DATA_PATH), steps=100)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Use groupwise dnn v2.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-12-10-16:18:03\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpm3tx4sz3/model.ckpt-100\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [10/100]\n",
            "INFO:tensorflow:Evaluation [20/100]\n",
            "INFO:tensorflow:Evaluation [30/100]\n",
            "INFO:tensorflow:Evaluation [40/100]\n",
            "INFO:tensorflow:Evaluation [50/100]\n",
            "INFO:tensorflow:Evaluation [60/100]\n",
            "INFO:tensorflow:Evaluation [70/100]\n",
            "INFO:tensorflow:Evaluation [80/100]\n",
            "INFO:tensorflow:Evaluation [90/100]\n",
            "INFO:tensorflow:Evaluation [100/100]\n",
            "INFO:tensorflow:Finished evaluation at 2018-12-10-16:18:17\n",
            "INFO:tensorflow:Saving dict for global step 100: global_step = 100, labels_mean = 0.777717, logits_mean = 0.41578826, loss = 1.6330168, metric/ndcg@1 = 0.5184375, metric/ndcg@10 = 0.7879902, metric/ndcg@3 = 0.6266924, metric/ndcg@5 = 0.75658303\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: /tmp/tmpm3tx4sz3/model.ckpt-100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'global_step': 100,\n",
              " 'labels_mean': 0.777717,\n",
              " 'logits_mean': 0.41578826,\n",
              " 'loss': 1.6330168,\n",
              " 'metric/ndcg@1': 0.5184375,\n",
              " 'metric/ndcg@10': 0.7879902,\n",
              " 'metric/ndcg@3': 0.6266924,\n",
              " 'metric/ndcg@5': 0.75658303}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "c4niImjz8l2v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualization\n",
        "\n",
        "The train and evaluation steps above by default store checkpoints, metrics, and other useful information about your network to a temporary directory on disk. We encourage you to visualize this data using [Tensorboard](http://www.tensorflow.org/guide/summaries_and_tensorboard). In particular, you can launch Tensorboard and point it to where your model data is stored as follows:\n",
        "\n",
        "First, let's find out the path to the log directory created by the process above."
      ]
    },
    {
      "metadata": {
        "id": "pGemb1op6AJj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "18366f1c-9160-4271-d7d9-1d6e114e25b9"
      },
      "cell_type": "code",
      "source": [
        "ranker.model_dir\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/tmp/tmpm3tx4sz3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "Ukorbpvo6Z_2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}